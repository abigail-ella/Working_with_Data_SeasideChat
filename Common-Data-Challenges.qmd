---
title: "Common Challenges Working With Data"
author: "Ward, A, Rivas, S., Shenasa, A."
format: 
  pdf: default
editor: visual
---

## The Burdens of Messy Data

Working with data can be frustrating. Collecting data is difficult and humans make mistakes meaning that often times the data we first begin to analyze and interpret can be full of flaws and mistakes. Programming languages aren't perfect either and need direction on how your data is formatted to be able to interpret it properly.

We have all experienced a time when messy data (either of our own doing or others) has nearly made us pull our hair out from frustration. This can be especially true when you're beginning to interact with a programming language for the first time. Our hope is to alleviate some of that stress and burden by giving some guidance on how to handle common data issues that can arise.

Here, we've narrowed down six of the more common challenges we have experienced while analyzing and visualizing data. We have broken down how these challenges may arise and given some suggestions and examples on how to proceed.

## Our Top Six Data Challenges

1.  ***Missing Data***

    In R, missing values in a data set are often represented by NA. This will either be from blank cells being filled in with NAs as the data frame is uploaded or if the uploaded data frame already contains NAs rather than blank cells. However, this can get messy for a number of reasons when NAs are mislabeled (i.e. N/A vs. N.A. vs. NA - which we deal with in our *Inconsistent Formatting* section), when you don't know how many missing values there are, or when they harm the visualization or interpretation of your data.

-   Checking data set for missing values

    If you have missing values in your data set, a good first step is simply to check for the presence of NAs. This will give an output of TRUE or FALSE based on the presence of missing values.

    ```{r}
    #| output: TRUE

    x <- c(8,12,NA,19,2,NA,99,4,78,1,32,NA)

    is.na(x)
    ```

-   Counting missing values

    Once the presence of NA values have been identified, we can check how many NA values are present. This can be especially helpful with larger data sets with many rows of data. This will give a number as an output of how many NA values are present.

    ```{r}
    #| output: TRUE
    y <- c(9,13,NA,24,17,15,3,NA,2,13,29,30,12,5,67,NA,92,46,73,NA,12,68,23,12,14,30,54,NA,12,90,43,21,68,54,3,2,90,52,12,NA,13,NA,24,17,15,3,NA,2,13,29,30,12,5,67,NA)

    sum(is.na(y))

    ```

-   Excluding missing values

    Omitting NA values can be an import step to ensuring standard R functions and statistical models run properly and avoid skewed results (depending on the source of NA values). Several functions like na.omit and na.rm can be used to exclude the missing values.

    na.omit removes missing values from the data (vector, matrix, or data frame). We can then check using sum(is.na()) to see if all NA values have been removed.

    ```{r}
    #| output: TRUE
    cleaned_y <- na.omit(y)

    sum(is.na(cleaned_y))
    ```

    Alternatively, na.rm can be used to ignore missing values during a calculation rather than removing them from the entire data set. This is an argument used within a function rather than a standalone function like na.omit. For example, when we try to take the mean of our data set with missing values, it returns "NA".

    ```{r}
    #| output: TRUE
    mean(y)
    ```

    But, if we include na.rm = TRUE, we can get the average without having to use our cleaned_y data set.

    ```{r}
    #| output: TRUE
    mean(y, na.rm = TRUE)
    mean(cleaned_y)
    ```

-   Replacing NAs

    Sometimes replacing NA values can be helpful either to approximate these values or to change them to a numeric value. If we wanted to replace all NAs in our vector with an average, we would simply take a subset of the vector that includes only NAs and set that equal to the value of our mean.

    ```{r}
    #| output: TRUE
    #Here we take all NAs in vector y and set them equal to our mean of y
    y[is.na(y)] <- mean(y, na.rm = TRUE)

    #View y
    y
    ```

2.  ***Inconsistent Formatting***

    One very common challenge when working with data is having inconsistent formatting in your data frame. This could mean values that mean the same thing are spelled differently, are abbreviated, or have varying capitalization. Not clearing up these issues early on can lead to confusing analyses and incorrect visualizations. Making sure your data is formatted well from the start of your data analysis journey will save many headaches in the long run.

    ```{r}
    messy_df <- data.frame(
      id = 1:10,
      color = c("Orange", "or", "orange ", "ORANGE", "blue", "Blue", "blu", "green", " Green", "green"),
      response = c("Yes", "yes", "YES", "No", "no", "NO", " yEs ", "nO", "Yes", "no"),
      score = c("1", "2", "three", "4", "5", "six", "7", "8", "nine", "10"),
      group = c("A", "a", "Group A", "B", "b ", "Group B", "C", "c", "Group C", "C")
    )

    ```

-   Inconsistent capitalization

    Values in a column can sometimes differ only by the capitalization of the letters. "No", "no", and "NO" will all be interpreted differently by R. Therefore, making this consistent is very important if these responses hold the same interpretation.

    ```{r}
    #| output: TRUE
    messy_df$response <- tolower(messy_df$response)

    messy_df$response
    ```

-   Leading or trailing spaces

    Inputting data manually can lead to additional spacing in places leading to unintended hidden characters. These sometimes will need to be removed to help with consistency in your data.

    ```{r}
    #| output: TRUE
    messy_df$color <- trimws(messy_df$color)
    messy_df$response <- trimws(messy_df$response)

    messy_df$color
    messy_df$response
    ```

-   Misspelled words/ multiple labels for one variable

    This will also lead to categorizing specific variables differently even if they are equivalent. But you can reformat your data to read them all as a single variable.

    ```{r}
    #| output: TRUE
    messy_df$color[messy_df$color == "or"] <- "orange"
    messy_df$color[messy_df$color == "blu"] <- "blue"

    messy_df$color
    ```

3.  ***Merging Dataframes***

    To properly analyze your data, you may need to combine multiple datasets that provide additional information or add more data. This can be done by adding more variables (i.e. columns) or by adding new observations (i.e. rows). A unified dataframe can simplify your data analysis process and lead to a cleaner workflow.

    ```{r}
    #Example data frames
    df_1<- data.frame(ID = 1:5, species = c("tiger","lion" , "jaguar", "lion", "tiger"))
    df_2<- data.frame(ID = 4:8, species= c("lion", "jaguar", "lion", "tiger", "tiger"), age = c(4, 2, 6, 1, 4))

    ```

-   Merging by columns

    Merging by columns is useful when two data frames contain different variables for the same observation. This can happen when data are collected from different sources or at different times but samples have the same ID.

    There are several types of joins available within the merge function. A left join keeps all rows from the first dataset and matching rows from the second. A right join includes all rows from the second dataset and matching rows from the first. An inner keeps only rows with matching keys in both datasets. And an outer keeps all rows from both datasets.

    ```{r}
    #Merging by columns by the ID

    #Keeps all rows from df_1 and adds matching data from df_2
    left_join <- merge(df_1, df_2, by = "ID", all.x = TRUE)

    #Keeps all rows from df_2 and adds matching data from df_1
    right_join <- merge(df_1, df_2, by = "ID", all.y = TRUE)

    #Keeps only rows where ID appears in both df_1 and df_2
    inner_join <- merge(df_1, df_2, by = "ID")

    #Keeps every row from both data frames
    full_join <- merge(df_1, df_2, by = "ID", all = TRUE)
    ```

-   Merging by row

    Merging by rows is important when two dataframes have the same variables but different observations, such as data collected at different times or from different locations. Both dataframes are supposed to have the same columns.

    ```{r}
    # Add missing column to df_1 so the structures match
    df_1$age <- NA

    merged_rows <- rbind(df_1, df_2)
    merged_rows

    ```

-   A word to the wise:

    -   Merging data frames can be both messy and scary work. It is a very common tool to merge data frames, but in order to make it a useful and efficient process here are a few useful tips!

    -   Know your data well! Use functions like head(), str(), and summary() to understand the column names, the type of data and the underlying structure of your data set.

    -   Understand merging types and how they fit your needs. The merge function allows for left, right, inner, and outer joins that all merge your data in varying ways. Know how these function and what suits your needs.

    -   Row binding errors can happen when data frames don’t have the same column names or types

3.  ***Mismatched Row/Column Length***s

4.  ***Incorrect Column Types***

In R, every column in a data frame has a data type (e.g., numeric, character, factor, Date). Problems happen when a column’s type doesn’t match how you want to use it. This often occurs when importing data from CSVs, Excel files, or mixed-format columns. Incorrect types can cause errors, misleading plots, or mistakes in calculations.

-   Numbers stored as characters When imputting data, sometimes columns of numbers are stored as characters (chr) or factors (factor), when you actually want them to be interpreted as numbers (num) or integers (int). This can cause problems when you try to do calculations, like finding the mean or plotting a variable.

    ```{r}
    #| output: TRUE
    df$temperature <- as.numeric(df$temperature) 
    ```

6.  ***Importing Data Error***

Importing your data set in R is typically the first step to begin your analysis. When importing data, there are several frustrating issues you may run into.

-   File path issues

    Your working directory is the default location where R will look for your files to load. Issues can arise when the current working directory is not where your files are, resulting in R being unable to locate your files. To check where your working directory is set to, we can use the function getwd()

    ```{r}
    #| output: TRUE
    getwd()
    ```

    If this is not the correct file path, we can then use setwd() to the intended file path.

    ```{r}
    #| output: TRUE
    setwd("/Users/aminashenasa/Working_with_Data_SeasideChat")
    ```

    Alternatively, to make the code accessible to users on different computers, you can use library(here) to reference the top-level of a directory of a file project rather than setwd() which only works on your own computer.

    ```{r}
    library(here)
    ```

-   Data format and structure issues

    Once we are able to locate and upload a file on R, issues regarding reading the file correctly may arise. The function read.csv() is for comma-separated files.

    ```{r}
    read.csv("PlantGrowth.csv")
    ```

    -   Alternative data files

        If your file uses a different separator, like tabs, semicolons, etc) you need to specify what delimiter is used. For tab separated files, we can use read.delim(), or we can use the readr package with the function read_tsv()

        For files with other delimiters, we can specify the correct separator using **read.csv(file, sep = ";")**
