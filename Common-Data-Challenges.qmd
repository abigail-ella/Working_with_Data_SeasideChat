---
title: "Common Challenges Working With Data"
author: "Ward, A, Rivas, S., Shenasa, A."
format: 
  pdf: default
editor: visual
---

## The Burdens of Messy Data

Working with data can be frustrating. Collecting data is difficult and humans make mistakes meaning that often times the data we first begin to analyze and interpret can be full of flaws and mistakes. Programming languages aren't perfect either and need direction on how your data is formatted to be able to interpret it properly.

We have all experienced a time when messy data (either of our own doing or others) has nearly made us pull our hair out from frustration. This can be especially true when you're beginning to interact with a programming language for the first time. Our hope is to alleviate some of that stress and burden by giving some guidance on how to handle common data issues that can arise.

Here, we've narrowed down six of the more common challenges we have experienced while analyzing and visualizing data. We have broken down how these challenges may arise and given some suggestions and examples on how to proceed.

## Our Top Six Data Challenges

1.  ***Missing Data***

    In R, missing values in a data set are often represented by NA. This will either be from blank cells being filled in with NAs as the data frame is uploaded or if the uploaded data frame already contains NAs rather than blank cells. However, this can get messy for a number of reasons when NAs are mislabeled (i.e. N/A vs. N.A. vs. NA - which we deal with in our *Inconsistent Formatting* section), when you don't know how many missing values there are, or when they harm the visualization or interpretation of your data.

-   Checking data set for missing values

    If you have missing values in your data set, a good first step is simply to check for the presence of NAs. This will give an output of TRUE or FALSE based on the presence of missing values.

    ```{r}
    #| output: TRUE

    x <- c(8,12,NA,19,2,NA,99,4,78,1,32,NA)

    is.na(x)
    ```

-   Counting missing values

    Once the presence of NA values have been identified, we can check how many NA values are present. This can be especially helpful with larger data sets with many rows of data. This will give a number as an output of how many NA values are present.

    ```{r}
    #| output: TRUE
    y <- c(9,13,NA,24,17,15,3,NA,2,13,29,30,12,5,67,NA,92,46,73,NA,12,68,23,12,14,30,54,NA,12,90,43,21,68,54,3,2,90,52,12,NA,13,NA,24,17,15,3,NA,2,13,29,30,12,5,67,NA)

    sum(is.na(y))

    ```

-   Excluding missing values

    Omitting NA values can be an import step to ensuring standard R functions and statistical models run properly and avoid skewed results (depending on the source of NA values). Several functions like na.omit and na.rm can be used to exclude the missing values.

    na.omit removes missing values from the data (vector, matrix, or data frame). We can then check using sum(is.na()) to see if all NA values have been removed.

    ```{r}
    #| output: TRUE
    cleaned_y <- na.omit(y)

    sum(is.na(cleaned_y))
    ```

    Alternatively, na.rm can be used to ignore missing values during a calculation rather than removing them from the entire data set. This is an argument used within a function rather than a standalone function like na.omit. For example, when we try to take the mean of our data set with missing values, it returns "NA".

    ```{r}
    #| output: TRUE
    mean(y)
    ```

    But, if we include na.rm = TRUE, we can get the average without having to use our cleaned_y data set.

    ```{r}
    #| output: TRUE
    mean(y, na.rm = TRUE)
    mean(cleaned_y)
    ```

-   Imputing NAs

2.  ***Inconsistent Formatting***

3.  ***Data Merging***

4.  ***Mismatched Row/Column Lengths***

5.  ***Incorrect Column Types***

6.  ***Importing Data Error***
